{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import SparsePCA \n",
    "\n",
    "import joblib \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LeL_utils import train_regressor, embeddings_preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaccusative = [\"appear\", \"arise\", \"awake\", \"come\", \"dawn\", \"emanate\", \"emerge\", \"erupt\", \"evolve\",\n",
    "                \"flow\", \"grow\", \"issue\", \"die\", \"materialize\", \"result\", \"rise\", \"stem\", \"stream\", \"supervene\",\n",
    "                \"surge\", \"wax\", \"disappear\", \"expire\", \"lapse\", \"perish\", \"vanish\", \"ensue\",\n",
    "                \"eventuate\", \"happen\", \"occur\", \"recur\", \"transpire\", \"abate\", \"advance\", \"age\", \"air\", \n",
    "                \"alter\", \"atrophy\", \"awake\", \"balance\", \"blur\", \n",
    "                \"burn\", \"burst\", \"capsize\", \"change\", \"clog\", \"close\", \"collapse\", \"collect\", \n",
    "                \"compress\", \"condense\", \"contract\", \"corrode\", \"crumble\", \"decompose\", \"decrease\", \n",
    "                \"deflate\", \"defrost\", \"degrade\", \"diminish\", \"dissolve\", \"distend\", \"divide\", \n",
    "                \"double\", \"drain\", \"ease\", \"enlarge\", \"expand\", \"explode\", \"fade\", \"fill\", \"flood\", \n",
    "                \"fray\", \"freeze\", \"fuse\", \"grow\", \"halt\", \"heal\", \"heat\", \"hush\", \"ignite\", \"improve\",\n",
    "                \"increase\", \"inflate\", \"kindle\", \"light\", \"mature\", \"melt\", \"multiply\", \"overturn\", \n",
    "                \"pop\", \"rekindle\", \"reproduce\", \"rupture\", \"scorch\", \"sear\", \"shrink\", \"shrivel\", \n",
    "                \"singe\", \"sink\", \"soak\", \"spray\", \"sprout\", \"steep\", \"stretch\", \"submerge\", \"subside\", \n",
    "                \"taper\", \"thaw\", \"tilt\", \"tire\", \"topple\", \"triple\", \"unfold\", \"vary\", \"warp\", \"clear\", \n",
    "                \"cool\", \"dim\", \"dry\", \"dull\", \"empty\", \"even\", \"level\", \"loosen\", \"mellow\", \"narrow\", \n",
    "                \"pale\", \"quiet\", \"shut\", \"slow\", \"smooth\", \"sober\", \"sour\", \"steady\", \"tense\", \n",
    "                \"triple\", \"warm\", \"break\", \"drift\", \"float\", \"glide\", \"move\", \"revolve\", \"rotate\", \"turn\", \n",
    "                \"break\", \"crack\", \"fracture\", \"rip\", \"shatter\", \"splinter\", \"split\", \"tear\", \"close\", \n",
    "                \"evaporate\", \"bend\", \"increase\", \"sink\", \"shrink\", \"drown\", \"break\", \"change\", \"drop\", \"fall\", \"die\"]\n",
    "\n",
    "unergative = [\"run\", \"talk\", \"resign\", \"work\", \"dance\", \"eat\", \"sleep\", \"walk\", \n",
    "              \"laugh\", \"shout\", \"caugh\", \"laugh\", \"fly\", \"sing\", \"yawn\", \"swim\"]\n",
    "\n",
    "intransitive = unaccusative+unergative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the semantic spaces for both arguments\n",
    "sspace_nsubj = pd.read_csv(\"..\\\\Data\\\\Semantic_Spaces\\\\sspace_spr2_nsubj.csv\", index_col = 'Token.Sent')\n",
    "sspace_dobj = pd.read_csv(\"..\\\\Data\\\\Semantic_Spaces\\\\sspace_spr2_dobj.csv\",  index_col = 'Token.Sent')\n",
    "properties = sspace_nsubj.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Regressor with BabyBERTa Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape for the transitive verb spac:(1856, 256)\n"
     ]
    }
   ],
   "source": [
    "#baby BERTa\n",
    "model_emb_path = \"target_embeddings_BabyBERTa-2.pkl\"\n",
    "bb_dict_nsubj, bb_dict_dobj, final_sspace_nsubj, final_sspace_dobj = embeddings_preparation(model_emb_path, \n",
    "                                                                    sspace_nsubj,\n",
    "                                                                    sspace_dobj, \n",
    "                                                                    model_name = \"BabyBERTa\",\n",
    "                                                                    return_new_sspace= True,\n",
    "                                                                    dir_path = \"..\\\\Data\\\\Extracted_Embeddings\")\n",
    "\n",
    "new_index = [i.split(\".\")[0].strip() for i in final_sspace_nsubj.index.tolist()]\n",
    "final_sspace_nsubj.index = new_index\n",
    "verbs2remove = [i for i in final_sspace_nsubj.index if i in intransitive]\n",
    "final_sspace_nsubj = final_sspace_nsubj.drop(verbs2remove)\n",
    "final_sspace_nsubj.shape\n",
    "\n",
    "bb_space_trans = pd.DataFrame(bb_dict_nsubj[\"BabyBERTa_nsubj\"]).set_axis(new_index).drop(verbs2remove)\n",
    "print(f\"New shape for the transitive verb spac:{bb_space_trans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n"
     ]
    }
   ],
   "source": [
    "#train the regrossor and save it\n",
    "regr = train_regressor(bb_space_trans, final_sspace_nsubj,\n",
    "                         sPca = False, save_model = True,\n",
    "                         model_name = \"BabyBERTa\",\n",
    "                         output_path = \"..\\\\Resgressors_NoSpca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Regressor with Pythia Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape for the transitive verb spac:(1856, 512)\n"
     ]
    }
   ],
   "source": [
    "#baby BERTa\n",
    "model_emb_path = \"target_embeddings_pythia-70m-deduped.pkl\"\n",
    "pythia_dict_nsubj, pythia_dict_dobj = embeddings_preparation(model_emb_path, \n",
    "                                                                    sspace_nsubj,\n",
    "                                                                    sspace_dobj, \n",
    "                                                                    model_name = \"Pythia70m\",\n",
    "                                                                    dir_path = \"..\\\\Data\\\\Extracted_Embeddings\")\n",
    "\n",
    "\n",
    "#reshape the model space for the transitive verbs\n",
    "pythia_space_trans = pd.DataFrame(pythia_dict_nsubj[\"Pythia70m_nsubj\"]).set_axis(new_index).drop(verbs2remove)\n",
    "print(f\"New shape for the transitive verb spac:{pythia_space_trans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n"
     ]
    }
   ],
   "source": [
    "#train the regrossor and save it\n",
    "regr = train_regressor(pythia_space_trans, final_sspace_nsubj,\n",
    "                         sPca = False, save_model = True,\n",
    "                         model_name = \"Pythia70m\",\n",
    "                         output_path = \"..\\\\Resgressors_NoSpca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Regressor with GPT2-XL Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape for the transitive verb spac:(1856, 1600)\n"
     ]
    }
   ],
   "source": [
    "#baby BERTa\n",
    "model_emb_path = \"target_embeddings_gpt2-xl.pkl\"\n",
    "gpt2xl_dict_nsubj, gpt2xl_dict_dobj = embeddings_preparation(model_emb_path, \n",
    "                                                                    sspace_nsubj,\n",
    "                                                                    sspace_dobj, \n",
    "                                                                    model_name = \"GPT2-XL\",\n",
    "                                                                    dir_path = \"..\\\\Data\\\\Extracted_Embeddings\")\n",
    "\n",
    "\n",
    "#reshape the model space for the transitive verbs\n",
    "gpt2xl_space_trans = pd.DataFrame(gpt2xl_dict_nsubj[\"GPT2-XL_nsubj\"]).set_axis(new_index).drop(verbs2remove)\n",
    "print(f\"New shape for the transitive verb spac:{gpt2xl_space_trans.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n"
     ]
    }
   ],
   "source": [
    "#train the regrossor and save it\n",
    "regr = train_regressor(gpt2xl_space_trans, final_sspace_nsubj,\n",
    "                         sPca = False, save_model = True,\n",
    "                         model_name = \"GPT2-XL_nospca\",\n",
    "                         output_path = \"..\\\\Resgressors_NoSpca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#load embeddings to predict\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m bb_ac_embs \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mData\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mExtracted_Embeddings_AC\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtarget_AC_embeddings_babyBERTa-2.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)) \n\u001b[0;32m      3\u001b[0m scaled_values \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlambda\u001b[39;00m x :(x\u001b[39m-\u001b[39mx\u001b[39m.\u001b[39mmin())\u001b[39m/\u001b[39m(x\u001b[39m.\u001b[39mmax()\u001b[39m-\u001b[39mx\u001b[39m.\u001b[39mmin()),bb_ac_embs\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m      5\u001b[0m \u001b[39m#make prediciton\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "#load embeddings to predict\n",
    "bb_ac_embs = pickle.load(open(\"..\\\\Data\\\\Extracted_Embeddings_AC\\\\target_AC_embeddings_babyBERTa-2.pkl\", \"rb\")) \n",
    "scaled_values = list(map(lambda x :(x-x.min())/(x.max()-x.min()),bb_ac_embs.values()))\n",
    "\n",
    "#make prediciton\n",
    "y = np.array(scaled_values)\n",
    "y_hat = regr.predict(y)\n",
    "\n",
    "#make prediction dataframe\n",
    "bb_predictions = pd.DataFrame(y_hat, columns = properties).set_axis(list(bb_ac_embs.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperLeL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
