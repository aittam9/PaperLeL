{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.decomposition import SparsePCA \n",
    "\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to estimate corrs \n",
    "def estimate_corrs(y_original, y_inferred, labels, corr_type):\n",
    "    \"\"\"\n",
    "    corr_type Ã¨ un parametro che specifica se la correlazione deve essere \n",
    "    calcolata tra le righe (\"byrow\") o tra le colonne (\"bycolumn\") delle due\n",
    "    matrici fornite in input\n",
    "    \n",
    "    In out fornisce sia la correlazione media che un Counter con le correlazioni puntuali\n",
    "    \"\"\"\n",
    "    corrs = Counter()\n",
    "        \n",
    "    if corr_type == \"byrow\":\n",
    "        for i in range(len(y_original)):\n",
    "            rho, _ = spearmanr(y_original[i], y_inferred[i])\n",
    "            corrs[labels[i]] = rho\n",
    "        \n",
    "    elif corr_type == \"bycolumn\":\n",
    "        for i in range(y_original.shape[1]):\n",
    "            rho, _ = spearmanr(y_original[:,i], y_inferred[:,i])\n",
    "            corrs[labels[i]] = rho\n",
    "                \n",
    "    average_rho = np.average(list(corrs.values()))\n",
    "        \n",
    "    return corrs, average_rho\n",
    "\n",
    "#helper function to load the embeddings and reshape them along with the sspace\n",
    "def embeddings_preparation(model_emb_path, sspace_nsubj , sspace_dobj, model_name = \"\", return_new_sspace = False):\n",
    "    \n",
    "    \"\"\"Parameters:\n",
    "    model_emb_path: name under wich embeddings are saved\n",
    "    sspace_nsubj: the sspace loaded for the nsubj\n",
    "    sspace_dobj: the sspace loaded for the dobj\n",
    "    model_name: the name of the model we are referringe to. Will be used to store the spaces with the right key.\n",
    "    return_new_sspace: parameter to decide if we want in output the reshaped sspaces. To be used the first time only.\n",
    "    \n",
    "    Output:\n",
    "    a dictionary containing two keys with respective values: the actual embedding space and a baseline with the same shape\n",
    "    new_sspace_nsubj, new_sspace_dobj: the reshaped target semantic spaces (only if param return_new_sspace =True)\n",
    "    \"\"\"\n",
    "    \n",
    "    #load the embeddings for the given model\n",
    "    dir_path = \"..\\\\Data\\\\Extracted_Embeddings\"\n",
    "    with open(os.path.join(dir_path,model_emb_path), \"rb\") as infile:\n",
    "        embeddings_dict = pickle.load(infile)\n",
    "    \n",
    "    #convert the dictionary into a dataframe\n",
    "    emb_df = pd.DataFrame(embeddings_dict).T \n",
    "    \n",
    "    #take the index of the semantic spaces to match the extracted verbs\n",
    "    verbs2keep_nsubj = sspace_nsubj.index.tolist()\n",
    "    verbs2keep_dobj = sspace_dobj.index.tolist()\n",
    "    \n",
    "    #filter the verbs from the target semantic space to match the embeddings spaces\n",
    "    model_nsubj = emb_df.filter(items = verbs2keep_nsubj, axis = 0).apply(lambda x:(x-x.min())/(x.max()-x.min()))\n",
    "    model_dobj = emb_df.filter(items = verbs2keep_dobj, axis = 0 ).apply(lambda x:(x-x.min())/(x.max()-x.min()))\n",
    "\n",
    "    #reverse the process to restrict the semantic spaces\n",
    "    sspace_nsubj_final = sspace_nsubj.filter(model_nsubj.index.tolist(), axis = 0)\n",
    "    sspace_dobbj_final = sspace_dobj.filter(model_dobj.index.tolist(), axis = 0)\n",
    "    \n",
    "    #store all the spaces along with a baseline in a dictionary\n",
    "    spaces_dict_nsubj = {}\n",
    "    spaces_dict_nsubj[model_name+\"_nsubj\"] = model_nsubj.values \n",
    "    spaces_dict_nsubj[model_name+\"_nsubj_baseline\"] = np.random.random_sample(model_nsubj.shape)\n",
    "    \n",
    "    # same for dobj\n",
    "    spaces_dict_dobj = {}\n",
    "    spaces_dict_dobj[model_name+\"_dobj\"] = model_dobj.values \n",
    "    spaces_dict_dobj[model_name+\"_dobj_baseline\"] = np.random.random_sample(model_dobj.shape)\n",
    "    \n",
    "    if return_new_sspace:\n",
    "        return spaces_dict_nsubj, spaces_dict_dobj, sspace_nsubj_final, sspace_dobbj_final\n",
    "    else:\n",
    "        return spaces_dict_nsubj, spaces_dict_dobj\n",
    "\n",
    "\n",
    "#helper function to automate correlations estimation\n",
    "def get_correlations_values(model_space:dict, semantic_space: pd.DataFrame, sPca = True):\n",
    "    \n",
    "    \"\"\"Parameters:\n",
    "    model_space: a dictionary containig 2 keys: the actual model embedding space for the gram argument(e.g. nsubj)\n",
    "                 and the random baseline shape as the model space.\n",
    "    semantic_space: a data frame the target semantic space for the referred gram argument. Will be used as y and to derive labels\n",
    "                    for corrs estimation.\n",
    "    sPCA: a boolean to decide if we want to transform the target space with sPCA. Default to True to reduce noise.\n",
    "    \n",
    "    Output:\n",
    "    Print average rhos values, by column and by row, for the embedding space and the baseline\n",
    "    all_corrs: puncutal correlations by row and column for model and baseline.\n",
    "    all_avg_rhos: average rhos by row and column, for model and baseline.\"\"\"\n",
    "    \n",
    "    # initialize the regressor and dictionary to be filled\n",
    "    pls = PLSRegression(n_components= 10)\n",
    "    all_corr = defaultdict(dict)\n",
    "    all_avg_rhos = defaultdict(dict)\n",
    "    y_pred = {}\n",
    "    #get the verbs and properties names, to be used as labels in corr estimation\n",
    "    verbs = semantic_space.index.tolist()\n",
    "    properties = semantic_space.columns.tolist()\n",
    "    \n",
    "    #initialize the sPCA and transform the target space if param not False\n",
    "    if sPca:\n",
    "        print(f\"Sparse PCA activated\\n\")\n",
    "        pca = SparsePCA(n_components=14)\n",
    "        y = pca.fit_transform(semantic_space.values)\n",
    "    else:\n",
    "        print(f\"Not using Sparse PCA\")\n",
    "        y = semantic_space.values\n",
    "        \n",
    "    # mapping for the given space\n",
    "    for k in model_space.keys():\n",
    "        X = model_space[k]\n",
    "        y = y\n",
    "        #get prediction values with cross validation k=10\n",
    "        y_pred[k] = cross_val_predict(pls, X, y, cv = 10)\n",
    "\n",
    "        # store and print correlation by row    \n",
    "        corrs, avg_rho = estimate_corrs(y,y_pred[k], verbs, 'byrow')\n",
    "        print(f\"Average row correlation for the {k} space: {avg_rho}\")\n",
    "\n",
    "        all_corr[k]['byrow'] = corrs\n",
    "        all_avg_rhos[k]['byrow'] = avg_rho\n",
    "\n",
    "        # store and print correlation by column\n",
    "        corrs, avg_rho = estimate_corrs(y,y_pred[k], properties, 'bycolumn')\n",
    "        print(f\"Average column correlation for the {k} space: {avg_rho}\\n\")\n",
    "\n",
    "        all_corr[k]['bycolumn'] = corrs\n",
    "        all_avg_rhos[k]['bycolumn'] = avg_rho\n",
    "\n",
    "    return all_corr, all_avg_rhos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(model_spaces:dict,target_sspace:pd.DataFrame, sPca = True, save_model = False, model_name = \"\"):\n",
    "    \"\"\"Params:\n",
    "    model_spaces: dicitonary containig the embeddings and baseline spaces.\n",
    "    target_sspace: the target nsubj sspace.\n",
    "    save_model: Boolean to control model saving.\n",
    "    model_name: empty string to be filled if model has to be saved\n",
    "    \n",
    "    Output:\n",
    "    regr: fitted regressor\n",
    "    saved model (if save_model = True)\"\"\"\n",
    "    \n",
    "    pls = PLSRegression(n_components=10)\n",
    "    X = list(model_spaces.values())[0]\n",
    "    \n",
    "    #transform y with sPca or not\n",
    "    if sPca:\n",
    "        print(f\"Sparse PCA activated\\n\")\n",
    "        pca = SparsePCA(n_components=14)\n",
    "        y = pca.fit_transform(target_sspace.values)\n",
    "    else:\n",
    "        print(f\"Not using Sparse PCA\")\n",
    "        y = target_sspace.values \n",
    "\n",
    "    regr = pls.fit(X,y)\n",
    "    \n",
    "    if save_model:\n",
    "        filename = \"pls_regr_\"+model_name\n",
    "        outdir = \"..\\\\Regressors\"\n",
    "        if not os.path.exists(outdir):\n",
    "            os.mkdir(outdir)\n",
    "        \n",
    "        with open(os.path.join(outdir, filename+\".pkl\"), \"wb\") as outfile:\n",
    "            joblib.dump(regr, outfile)\n",
    "    \n",
    "    return regr\n",
    "\n",
    "#helper function to aggregate all correlation results in a unique dataframe\n",
    "def aggregate_results(list_of_dict, save_results = False, file_name = \"\"):\n",
    "    outdir = \"..\\\\Data\\\\Correlations\"\n",
    "    df = pd.concat([pd.DataFrame(i).T for i in list_of_dict])\n",
    "    \n",
    "    if save_results:\n",
    "        file_name = file_name+\".csv\"\n",
    "        df.to_csv(os.path.join(outdir,file_name), sep = \"\\t\")\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the semantic spaces for both arguments\n",
    "sspace_nsubj = pd.read_csv(\"..\\\\Data\\\\Semantic_Spaces\\\\sspace_spr2_nsubj.csv\", index_col = 'Token.Sent')\n",
    "sspace_dobj = pd.read_csv(\"..\\\\Data\\\\Semantic_Spaces\\\\sspace_spr2_dobj.csv\",  index_col = 'Token.Sent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping BabyBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the BabyBERTa_nsubj space: 0.3454790023254753\n",
      "Average column correlation for the BabyBERTa_nsubj space: 0.3570435498045595\n",
      "\n",
      "Average row correlation for the BabyBERTa_nsubj_baseline space: -0.026640372076056726\n",
      "Average column correlation for the BabyBERTa_nsubj_baseline space: -0.03443351206489502\n",
      "\n",
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the BabyBERTa_dobj space: 0.1994090416625628\n",
      "Average column correlation for the BabyBERTa_dobj space: 0.20121971805471586\n",
      "\n",
      "Average row correlation for the BabyBERTa_dobj_baseline space: -0.04497192947897173\n",
      "Average column correlation for the BabyBERTa_dobj_baseline space: -0.04283471976351089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#baby BERTa\n",
    "model_emb_path = \"target_embeddings_BabyBERTa-2.pkl\"\n",
    "bb_dict_nsubj, bb_dict_dobj, final_sspace_nsubj, final_sspace_dobj = embeddings_preparation(model_emb_path, \n",
    "                                                                    sspace_nsubj,\n",
    "                                                                    sspace_dobj, \n",
    "                                                                    model_name = \"BabyBERTa\",\n",
    "                                                                    return_new_sspace= True)\n",
    "\n",
    "bb_corrs_nsubj, bb_avgr_nsubj = get_correlations_values(bb_dict_nsubj, final_sspace_nsubj)\n",
    "bb_corrs_dobj, bb_avgr_dobj = get_correlations_values(bb_dict_dobj, final_sspace_dobj)\n",
    "\n",
    "#aggregate_results([bb_avgr_nsubj,bb_avgr_dobj], save_results = True, file_name = babyBERTa_avgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n",
      "Average row correlation for the BabyBERTa_nsubj space: 0.7710238419553743\n",
      "Average column correlation for the BabyBERTa_nsubj space: 0.3570464734001003\n",
      "\n",
      "Average row correlation for the BabyBERTa_nsubj_baseline space: 0.7079004224299861\n",
      "Average column correlation for the BabyBERTa_nsubj_baseline space: -0.018589531823358273\n",
      "\n",
      "Not using Sparse PCA\n",
      "Average row correlation for the BabyBERTa_dobj space: 0.6575879560911262\n",
      "Average column correlation for the BabyBERTa_dobj space: 0.20120690436413316\n",
      "\n",
      "Average row correlation for the BabyBERTa_dobj_baseline space: 0.5645505268416493\n",
      "Average column correlation for the BabyBERTa_dobj_baseline space: -0.03241292901561521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# no sPCA\n",
    "bb_corrs_nsubj, bb_avgr_nsubj = get_correlations_values(bb_dict_nsubj, final_sspace_nsubj,sPca = False)\n",
    "bb_corrs_dobj, bb_avgr_dobj = get_correlations_values(bb_dict_dobj, final_sspace_dobj, sPca = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a regressor\n",
    "bb_regr = train_regressor(bb_dict_nsubj,final_sspace_nsubj, save_model= True, model_name= \"babyBERTa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the Pythia70m_nsubj space: 0.40719985408782094\n",
      "Average column correlation for the Pythia70m_nsubj space: 0.3987736007744081\n",
      "\n",
      "Average row correlation for the Pythia70m_nsubj_baseline space: -0.02140577265058593\n",
      "Average column correlation for the Pythia70m_nsubj_baseline space: -0.01697139281683269\n",
      "\n",
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the Pythia70m_dobj space: 0.21492591915127127\n",
      "Average column correlation for the Pythia70m_dobj space: 0.21103843645134115\n",
      "\n",
      "Average row correlation for the Pythia70m_dobj_baseline space: -0.012480477269209658\n",
      "Average column correlation for the Pythia70m_dobj_baseline space: -0.00791572584138237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pythia\n",
    "model_emb_path = \"target_embeddings_pythia-70m-deduped.pkl\"\n",
    "pythia_dict_nsubj, pythia_dict_dobj= embeddings_preparation(model_emb_path, \n",
    "                                                    sspace_nsubj,\n",
    "                                                    sspace_dobj, \n",
    "                                                    model_name = \"Pythia70m\"\n",
    "                                                    )\n",
    "\n",
    "pythia_corrs_nsubj, pythia_avgr_nsubj = get_correlations_values(pythia_dict_nsubj, final_sspace_nsubj)\n",
    "pythia_corrs_dobj, pythia_avgr_dobj = get_correlations_values(pythia_dict_dobj, final_sspace_dobj)\n",
    "\n",
    "#aggregate_results([pythia_avgr_nsubj,pythia_avgr_dobj], save_results = True, file_name = Pythia70m_avgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n",
      "Average row correlation for the Pythia70m_nsubj space: 0.7816389431104404\n",
      "Average column correlation for the Pythia70m_nsubj space: 0.39878595139884104\n",
      "\n",
      "Average row correlation for the Pythia70m_nsubj_baseline space: 0.6869785933114928\n",
      "Average column correlation for the Pythia70m_nsubj_baseline space: -0.016999105149870172\n",
      "\n",
      "Not using Sparse PCA\n",
      "Average row correlation for the Pythia70m_dobj space: 0.6682005261153099\n",
      "Average column correlation for the Pythia70m_dobj space: 0.21107765574626722\n",
      "\n",
      "Average row correlation for the Pythia70m_dobj_baseline space: 0.5479877990161518\n",
      "Average column correlation for the Pythia70m_dobj_baseline space: -0.008249606870172932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pythia_corrs_nsubj, pythia_avgr_nsubj = get_correlations_values(pythia_dict_nsubj, final_sspace_nsubj, sPca = False)\n",
    "pythia_corrs_dobj, pythia_avgr_dobj = get_correlations_values(pythia_dict_dobj, final_sspace_dobj,sPca = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a regressor\n",
    "pythia_regr = train_regressor(pythia_dict_nsubj,final_sspace_nsubj, save_model= True, model_name= \"Pythia70m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping GPT2-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the GPT2-XL_nsubj space: 0.4234804614472664\n",
      "Average column correlation for the GPT2-XL_nsubj space: 0.4076927006612456\n",
      "\n",
      "Average row correlation for the GPT2-XL_nsubj_baseline space: -0.00731840773334549\n",
      "Average column correlation for the GPT2-XL_nsubj_baseline space: -0.0008493025021799626\n",
      "\n",
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the GPT2-XL_dobj space: 0.2559327995947714\n",
      "Average column correlation for the GPT2-XL_dobj space: 0.26106065176527615\n",
      "\n",
      "Average row correlation for the GPT2-XL_dobj_baseline space: -0.026044378157054213\n",
      "Average column correlation for the GPT2-XL_dobj_baseline space: -0.020931897352724566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GPT2-XL\n",
    "model_emb_path = \"target_embeddings_gpt2-xl.pkl\"\n",
    "gpt2xl_dict_nsubj, gpt2xl_dict_dobj= embeddings_preparation(model_emb_path, \n",
    "                                                    sspace_nsubj,\n",
    "                                                    sspace_dobj, \n",
    "                                                    model_name = \"GPT2-XL\"\n",
    "                                                    )\n",
    "\n",
    "gpt2xl_corrs_nsubj, gpt2xl_avgr_nsubj = get_correlations_values(gpt2xl_dict_nsubj, final_sspace_nsubj)\n",
    "gpt2xl_corrs_dobj, gpt2xl_avgr_dobj = get_correlations_values(gpt2xl_dict_dobj, final_sspace_dobj)\n",
    "\n",
    "#aggregate_results([gpt2xl_avgr_nsubj,gpt2xl_avgr_dobj], save_results = True, file_name = GPT2-XL_avgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n",
      "Average row correlation for the GPT2-XL_nsubj space: 0.7870254165356915\n",
      "Average column correlation for the GPT2-XL_nsubj space: 0.4077370644255654\n",
      "\n",
      "Average row correlation for the GPT2-XL_nsubj_baseline space: 0.6539906945969608\n",
      "Average column correlation for the GPT2-XL_nsubj_baseline space: -0.0008460060457187347\n",
      "\n",
      "Not using Sparse PCA\n",
      "Average row correlation for the GPT2-XL_dobj space: 0.6824411759289376\n",
      "Average column correlation for the GPT2-XL_dobj space: 0.26109680628558146\n",
      "\n",
      "Average row correlation for the GPT2-XL_dobj_baseline space: 0.5649349274801263\n",
      "Average column correlation for the GPT2-XL_dobj_baseline space: -0.020835481530775905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2xl_corrs_nsubj, gpt2xl_avgr_nsubj = get_correlations_values(gpt2xl_dict_nsubj, final_sspace_nsubj, sPca = False)\n",
    "gpt2xl_corrs_dobj, gpt2xl_avgr_dobj = get_correlations_values(gpt2xl_dict_dobj, final_sspace_dobj, sPca = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a regressor\n",
    "gpt2xl_regr = train_regressor(gpt2xl_dict_nsubj,final_sspace_nsubj, save_model= True, model_name= \"GPT2-XL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate all the results in a unique df\n",
    "aggregate_results([bb_avgr_nsubj,bb_avgr_dobj,\n",
    "                   pythia_avgr_nsubj,pythia_avgr_dobj,\n",
    "                   gpt2xl_avgr_nsubj, gpt2xl_avgr_dobj], save_results= True, file_name = \"all_avgr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperLeL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
