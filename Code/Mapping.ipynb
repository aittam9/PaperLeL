{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.decomposition import SparsePCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to estimate corrs \n",
    "def estimate_corrs(y_original, y_inferred, labels, corr_type):\n",
    "    \"\"\"\n",
    "    corr_type Ã¨ un parametro che specifica se la correlazione deve essere \n",
    "    calcolata tra le righe (\"byrow\") o tra le colonne (\"bycolumn\") delle due\n",
    "    matrici fornite in input\n",
    "    \n",
    "    In out fornisce sia la correlazione media che un Counter con le correlazioni puntuali\n",
    "    \"\"\"\n",
    "    corrs = Counter()\n",
    "        \n",
    "    if corr_type == \"byrow\":\n",
    "        for i in range(len(y_original)):\n",
    "            rho, _ = spearmanr(y_original[i], y_inferred[i])\n",
    "            corrs[labels[i]] = rho\n",
    "        \n",
    "    elif corr_type == \"bycolumn\":\n",
    "        for i in range(y_original.shape[1]):\n",
    "            rho, _ = spearmanr(y_original[:,i], y_inferred[:,i])\n",
    "            corrs[labels[i]] = rho\n",
    "                \n",
    "    average_rho = np.average(list(corrs.values()))\n",
    "        \n",
    "    return corrs, average_rho\n",
    "\n",
    "#helper function to load the embeddings and reshape them along with the sspace\n",
    "def embeddings_preparation(model_emb_path, sspace_nsubj , sspace_dobj, model_name = \"\", return_new_sspace = False):\n",
    "    \n",
    "    \"\"\"Parameters:\n",
    "    model_emb_path: name under wich embeddings are saved\n",
    "    sspace_nsubj: the sspace loaded for the nsubj\n",
    "    sspace_dobj: the sspace loaded for the dobj\n",
    "    model_name: the name of the model we are referringe to. Will be used to store the spaces with the right key.\n",
    "    return_new_sspace: parameter to decide if we want in output the reshaped sspaces. To be used the first time only.\n",
    "    \"\"\"\n",
    "    \n",
    "    #load the embeddings for the given model\n",
    "    dir_path = \"..\\\\Data\\\\Extracted_Embeddings\"\n",
    "    with open(os.path.join(dir_path,model_emb_path), \"rb\") as infile:\n",
    "        embeddings_dict = pickle.load(infile)\n",
    "    \n",
    "    #convert the dictionary into a dataframe\n",
    "    emb_df = pd.DataFrame(embeddings_dict).T \n",
    "    \n",
    "    #take the index of the semantic spaces to match the extracted verbs\n",
    "    verbs2keep_nsubj = sspace_nsubj.index.tolist()\n",
    "    verbs2keep_dobj = sspace_dobj.index.tolist()\n",
    "    \n",
    "    #filter the verbs from the target semantic space to match the embeddings spaces\n",
    "    model_nsubj = emb_df.filter(items = verbs2keep_nsubj, axis = 0).apply(lambda x:(x-x.min())/(x.max()-x.min()))\n",
    "    model_dobj = emb_df.filter(items = verbs2keep_dobj, axis = 0 ).apply(lambda x:(x-x.min())/(x.max()-x.min()))\n",
    "\n",
    "    #reverse the process to restrict the semantic spaces\n",
    "    sspace_nsubj_final = sspace_nsubj.filter(model_nsubj.index.tolist(), axis = 0)\n",
    "    sspace_dobbj_final = sspace_dobj.filter(model_dobj.index.tolist(), axis = 0)\n",
    "    \n",
    "    #store all the spaces along with a baseline in a dictionary\n",
    "    spaces_dict_nsubj = {}\n",
    "    spaces_dict_nsubj[model_name+\"_nsubj\"] = model_nsubj.values \n",
    "    spaces_dict_nsubj[model_name+\"_nsubj_baseline\"] = np.random.random_sample(model_nsubj.shape)\n",
    "    \n",
    "    # same for dobj\n",
    "    spaces_dict_dobj = {}\n",
    "    spaces_dict_dobj[model_name+\"_dobj\"] = model_dobj.values \n",
    "    spaces_dict_dobj[model_name+\"_dobj_baseline\"] = np.random.random_sample(model_dobj.shape)\n",
    "    \n",
    "    if return_new_sspace:\n",
    "        return spaces_dict_nsubj, spaces_dict_dobj, sspace_nsubj_final, sspace_dobbj_final\n",
    "    else:\n",
    "        return spaces_dict_nsubj, spaces_dict_dobj\n",
    "\n",
    "\n",
    "#helper function to automate correlations estimation\n",
    "def get_correlations_values(model_space:dict, semantic_space: pd.DataFrame, sPca = True):\n",
    "    \n",
    "    \"\"\"Parameters:\n",
    "    model_space: a dictionary containig 2 keys: the actual model embedding space for the gram argument(e.g. nsubj)\n",
    "                 and the random baseline shape as the model space.\n",
    "    semantic_space: a data frame the target semantic space for the referred gram argument. Will be used as y and to derive labels\n",
    "                    for corrs estimation.\n",
    "    sPCA: a boolean to decide if we want to transform the target space with sPCA. Default to True to reduce noise.\"\"\"\n",
    "    \n",
    "    # initialize the regressor and dictionary to be filled\n",
    "    pls = PLSRegression(n_components= 10)\n",
    "    all_corr = defaultdict(dict)\n",
    "    all_avg_rhos = defaultdict(dict)\n",
    "    y_pred = {}\n",
    "    #get the verbs and properties names, to be used as labels in corr estimation\n",
    "    verbs = semantic_space.index.tolist()\n",
    "    properties = semantic_space.columns.tolist()\n",
    "    \n",
    "    #initialize the sPCA and transform the target space if param not False\n",
    "    if sPca:\n",
    "        print(f\"Sparse PCA activated\\n\")\n",
    "        pca = SparsePCA(n_components=14)\n",
    "        y = pca.fit_transform(semantic_space.values)\n",
    "    else:\n",
    "        print(f\"Not using Sparse PCA\")\n",
    "        y = semantic_space.values\n",
    "        \n",
    "    # mapping for the given space\n",
    "    for k in model_space.keys():\n",
    "        X = model_space[k]\n",
    "        y = y\n",
    "        #get prediction values with cross validation k=10\n",
    "        y_pred[k] = cross_val_predict(pls, X, y, cv = 10)\n",
    "\n",
    "        # store and print correlation by row    \n",
    "        corrs, avg_rho = estimate_corrs(y,y_pred[k], verbs, 'byrow')\n",
    "        print(f\"Average row correlation for the {k} space: {avg_rho}\")\n",
    "\n",
    "        all_corr[k]['byrow'] = corrs\n",
    "        all_avg_rhos[k]['byrow'] = avg_rho\n",
    "\n",
    "        # store and print correlation by column\n",
    "        corrs, avg_rho = estimate_corrs(y,y_pred[k], properties, 'bycolumn')\n",
    "        print(f\"Average column correlation for the {k} space: {avg_rho}\\n\")\n",
    "\n",
    "        all_corr[k]['bycolumn'] = corrs\n",
    "        all_avg_rhos[k]['bycolumn'] = avg_rho\n",
    "\n",
    "    return all_corr, all_avg_rhos\n",
    "\n",
    "def write_corrs(all_avg_rhos):\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload the semantic spaces for both arguments\n",
    "sspace_nsubj = pd.read_csv(\"..\\\\Data\\\\Semantic_Spaces\\\\sspace_spr2_nsubj.csv\", index_col = 'Token.Sent')\n",
    "sspace_dobj = pd.read_csv(\"..\\\\Data\\\\Semantic_Spaces\\\\sspace_spr2_dobj.csv\",  index_col = 'Token.Sent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping BabyBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the BabyBERTa_nsubj space: 0.3454790023254753\n",
      "Average column correlation for the BabyBERTa_nsubj space: 0.3570435498045595\n",
      "\n",
      "Average row correlation for the BabyBERTa_nsubj_baseline space: -0.004751265332178196\n",
      "Average column correlation for the BabyBERTa_nsubj_baseline space: -0.018592378507054187\n",
      "\n",
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the BabyBERTa_dobj space: 0.1994090416625628\n",
      "Average column correlation for the BabyBERTa_dobj space: 0.20121971805471586\n",
      "\n",
      "Average row correlation for the BabyBERTa_dobj_baseline space: -0.03594996552743032\n",
      "Average column correlation for the BabyBERTa_dobj_baseline space: -0.03244091461116801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#baby BERTa\n",
    "model_emb_path = \"target_embeddings_BabyBERTa-2.pkl\"\n",
    "bb_dict_nsubj, bb_dict_dobj, final_sspace_nsubj, final_sspace_dobj = embeddings_preparation(model_emb_path, \n",
    "                                                                    sspace_nsubj,\n",
    "                                                                    sspace_dobj, \n",
    "                                                                    model_name = \"BabyBERTa\",\n",
    "                                                                    return_new_sspace= True)\n",
    "\n",
    "bb_corrs_nsubj, bb_avgr_nsubj = get_correlations_values(bb_dict_nsubj, final_sspace_nsubj)\n",
    "bb_corrs_dobj, bb_avgr_dobj = get_correlations_values(bb_dict_dobj, final_sspace_dobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n",
      "Average row correlation for the BabyBERTa_nsubj space: 0.7710238419553743\n",
      "Average column correlation for the BabyBERTa_nsubj space: 0.3570464734001003\n",
      "\n",
      "Average row correlation for the BabyBERTa_nsubj_baseline space: 0.7079004224299861\n",
      "Average column correlation for the BabyBERTa_nsubj_baseline space: -0.018589531823358273\n",
      "\n",
      "Not using Sparse PCA\n",
      "Average row correlation for the BabyBERTa_dobj space: 0.6575879560911262\n",
      "Average column correlation for the BabyBERTa_dobj space: 0.20120690436413316\n",
      "\n",
      "Average row correlation for the BabyBERTa_dobj_baseline space: 0.5645505268416493\n",
      "Average column correlation for the BabyBERTa_dobj_baseline space: -0.03241292901561521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bb_corrs_nsubj, bb_avgr_nsubj = get_correlations_values(bb_dict_nsubj, final_sspace_nsubj,sPca = False)\n",
    "bb_corrs_dobj, bb_avgr_dobj = get_correlations_values(bb_dict_dobj, final_sspace_dobj, sPca = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Pythia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the Pythia70m_nsubj space: 0.40719985408782094\n",
      "Average column correlation for the Pythia70m_nsubj space: 0.3987736007744081\n",
      "\n",
      "Average row correlation for the Pythia70m_nsubj_baseline space: -0.02140577265058593\n",
      "Average column correlation for the Pythia70m_nsubj_baseline space: -0.01697139281683269\n",
      "\n",
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the Pythia70m_dobj space: 0.21492591915127127\n",
      "Average column correlation for the Pythia70m_dobj space: 0.21103843645134115\n",
      "\n",
      "Average row correlation for the Pythia70m_dobj_baseline space: -0.012480477269209658\n",
      "Average column correlation for the Pythia70m_dobj_baseline space: -0.00791572584138237\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Pythia\n",
    "model_emb_path = \"target_embeddings_pythia-70m-deduped.pkl\"\n",
    "pythia_dict_nsubj, pythia_dict_dobj= embeddings_preparation(model_emb_path, \n",
    "                                                    sspace_nsubj,\n",
    "                                                    sspace_dobj, \n",
    "                                                    model_name = \"Pythia70m\"\n",
    "                                                    )\n",
    "\n",
    "pythia_corrs_nsubj, pythia_avgr_nsubj = get_correlations_values(pythia_dict_nsubj, final_sspace_nsubj)\n",
    "pythia_corrs_dobj, pythia_avgr_dobj = get_correlations_values(pythia_dict_dobj, final_sspace_dobj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n",
      "Average row correlation for the Pythia70m_nsubj space: 0.7816389431104404\n",
      "Average column correlation for the Pythia70m_nsubj space: 0.39878595139884104\n",
      "\n",
      "Average row correlation for the Pythia70m_nsubj_baseline space: 0.6869785933114928\n",
      "Average column correlation for the Pythia70m_nsubj_baseline space: -0.016999105149870172\n",
      "\n",
      "Not using Sparse PCA\n",
      "Average row correlation for the Pythia70m_dobj space: 0.6682005261153099\n",
      "Average column correlation for the Pythia70m_dobj space: 0.21107765574626722\n",
      "\n",
      "Average row correlation for the Pythia70m_dobj_baseline space: 0.5479877990161518\n",
      "Average column correlation for the Pythia70m_dobj_baseline space: -0.008249606870172932\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pythia_corrs_nsubj, pythia_avgr_nsubj = get_correlations_values(pythia_dict_nsubj, final_sspace_nsubj, sPca = False)\n",
    "pythia_corrs_dobj, pythia_avgr_dobj = get_correlations_values(pythia_dict_dobj, final_sspace_dobj,sPca = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping GPT2-XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the GPT2-XL_nsubj space: 0.4234804614472664\n",
      "Average column correlation for the GPT2-XL_nsubj space: 0.4076927006612456\n",
      "\n",
      "Average row correlation for the GPT2-XL_nsubj_baseline space: -0.00731840773334549\n",
      "Average column correlation for the GPT2-XL_nsubj_baseline space: -0.0008493025021799626\n",
      "\n",
      "Sparse PCA activated\n",
      "\n",
      "Average row correlation for the GPT2-XL_dobj space: 0.2559327995947714\n",
      "Average column correlation for the GPT2-XL_dobj space: 0.26106065176527615\n",
      "\n",
      "Average row correlation for the GPT2-XL_dobj_baseline space: -0.026044378157054213\n",
      "Average column correlation for the GPT2-XL_dobj_baseline space: -0.020931897352724566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GPT2-XL\n",
    "model_emb_path = \"target_embeddings_gpt2-xl.pkl\"\n",
    "gpt2xl_dict_nsubj, gpt2xl_dict_dobj= embeddings_preparation(model_emb_path, \n",
    "                                                    sspace_nsubj,\n",
    "                                                    sspace_dobj, \n",
    "                                                    model_name = \"GPT2-XL\"\n",
    "                                                    )\n",
    "\n",
    "gpt2xl_corrs_nsubj, gpt2xl_avgr_nsubj = get_correlations_values(gpt2xl_dict_nsubj, final_sspace_nsubj)\n",
    "gpt2xl_corrs_dobj, gpt2xl_avgr_dobj = get_correlations_values(gpt2xl_dict_dobj, final_sspace_dobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using Sparse PCA\n",
      "Average row correlation for the GPT2-XL_nsubj space: 0.7870254165356915\n",
      "Average column correlation for the GPT2-XL_nsubj space: 0.4077370644255654\n",
      "\n",
      "Average row correlation for the GPT2-XL_nsubj_baseline space: 0.6539906945969608\n",
      "Average column correlation for the GPT2-XL_nsubj_baseline space: -0.0008460060457187347\n",
      "\n",
      "Not using Sparse PCA\n",
      "Average row correlation for the GPT2-XL_dobj space: 0.6824411759289376\n",
      "Average column correlation for the GPT2-XL_dobj space: 0.26109680628558146\n",
      "\n",
      "Average row correlation for the GPT2-XL_dobj_baseline space: 0.5649349274801263\n",
      "Average column correlation for the GPT2-XL_dobj_baseline space: -0.020835481530775905\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt2xl_corrs_nsubj, gpt2xl_avgr_nsubj = get_correlations_values(gpt2xl_dict_nsubj, final_sspace_nsubj, sPca = False)\n",
    "gpt2xl_corrs_dobj, gpt2xl_avgr_dobj = get_correlations_values(gpt2xl_dict_dobj, final_sspace_dobj, sPca = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperLeL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
